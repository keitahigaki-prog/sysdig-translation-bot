#!/usr/bin/env python3
"""
Sysdigå…¨é¡§å®¢äº‹ä¾‹ãƒªã‚¹ãƒˆå–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
https://www.sysdig.com/customers ã‹ã‚‰å…¨104äº‹ä¾‹ã‚’å–å¾—
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from typing import List, Dict

def fetch_all_customer_stories() -> List[Dict]:
    """
    Sysdigé¡§å®¢äº‹ä¾‹ãƒšãƒ¼ã‚¸ã‹ã‚‰å…¨äº‹ä¾‹ã‚’å–å¾—
    """
    base_url = "https://www.sysdig.com"
    customers_url = f"{base_url}/customers"

    print(f"ğŸŒ {customers_url} ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")

    try:
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šã—ã¦ã‚¢ã‚¯ã‚»ã‚¹
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        response = requests.get(customers_url, headers=headers, timeout=30)
        response.raise_for_status()

        print(f"âœ… ãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code})")

        # HTMLã‚’ãƒ‘ãƒ¼ã‚¹
        soup = BeautifulSoup(response.content, 'html.parser')

        # é¡§å®¢äº‹ä¾‹ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        articles = []

        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: /customers/ã§å§‹ã¾ã‚‹ãƒªãƒ³ã‚¯
        for link in soup.find_all('a', href=True):
            href = link.get('href')

            if href and '/customers/' in href and href != '/customers' and href != '/customers/':
                # URLã‚’æ­£è¦åŒ–
                if href.startswith('/'):
                    full_url = base_url + href
                    slug = href.replace('/customers/', '').strip('/')
                elif href.startswith('http'):
                    full_url = href
                    slug = href.split('/customers/')[-1].strip('/')
                else:
                    continue

                # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                slug = slug.split('?')[0].split('#')[0]
                full_url = full_url.split('?')[0].split('#')[0]

                if not slug or slug == 'customers':
                    continue

                # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
                title = link.get_text(strip=True)
                if not title:
                    # ãƒªãƒ³ã‚¯ã®è¦ªè¦ç´ ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¢ã™
                    parent = link.find_parent(['div', 'article', 'section'])
                    if parent:
                        title_elem = parent.find(['h1', 'h2', 'h3', 'h4'])
                        if title_elem:
                            title = title_elem.get_text(strip=True)

                if not title or len(title) < 3:
                    # slugã‹ã‚‰æ¨æ¸¬
                    title = slug.replace('-', ' ').title()

                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if not any(a['slug'] == slug for a in articles):
                    articles.append({
                        'slug': slug,
                        'title': title,
                        'url': full_url
                    })

        print(f"ğŸ“Š {len(articles)} ä»¶ã®äº‹ä¾‹ã‚’ç™ºè¦‹")

        # ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ã¨ã‚½ãƒ¼ãƒˆ
        unique_articles = []
        seen_slugs = set()

        for article in articles:
            if article['slug'] not in seen_slugs:
                unique_articles.append(article)
                seen_slugs.add(article['slug'])

        unique_articles.sort(key=lambda x: x['slug'])

        return unique_articles

    except requests.exceptions.RequestException as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def save_to_json(articles: List[Dict], filename: str = "all_articles.json"):
    """è¨˜äº‹ãƒªã‚¹ãƒˆã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(articles, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ ({len(articles)}ä»¶)")

def update_shell_script(articles: List[Dict]):
    """translate_simple.sh ã‚’æ›´æ–°"""

    # ARTICLESå¤‰æ•°ã‚’ç”Ÿæˆ
    articles_lines = []
    for article in articles:
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
        title = article['title'].replace('"', '\\"')
        articles_lines.append(f'{article["slug"]}|{title}')

    articles_content = '\n'.join(articles_lines)

    print(f"\nğŸ“ translate_simple.sh ç”¨ã® ARTICLES å¤‰æ•°:")
    print(f"\nARTICLES=\"")
    print(articles_content)
    print(f"\"")
    print(f"\nå…¨ {len(articles)} ä»¶")

def main():
    print("ğŸš€ Sysdigå…¨é¡§å®¢äº‹ä¾‹å–å¾—ãƒ„ãƒ¼ãƒ«")
    print("="*60)
    print()

    # å…¨äº‹ä¾‹ã‚’å–å¾—
    articles = fetch_all_customer_stories()

    if not articles:
        print("âš ï¸  äº‹ä¾‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    # JSONã«ä¿å­˜
    save_to_json(articles)

    # ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”¨ã®å‡ºåŠ›
    update_shell_script(articles)

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "="*60)
    print("ğŸ“Š ã‚µãƒãƒªãƒ¼")
    print("="*60)
    print(f"ç™ºè¦‹ã—ãŸäº‹ä¾‹æ•°: {len(articles)}")
    print(f"ä¿å­˜å…ˆ: all_articles.json")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. all_articles.json ã‚’ç¢ºèª")
    print("  2. translate_simple.sh ã® ARTICLES å¤‰æ•°ã‚’æ›´æ–°")
    print("  3. ç¿»è¨³ã‚’å®Ÿè¡Œ")

if __name__ == "__main__":
    main()
